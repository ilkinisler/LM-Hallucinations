{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import argparse\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def retrieve_documents(query, documents, index, k=3):\n",
    "    \"\"\"Retrieve the top-k most relevant documents for a given query.\"\"\"\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "    _, indices = index.search(query_embedding, k)\n",
    "    return [documents[i] for i in indices[0]]\n",
    "\n",
    "def generate_response(prompt, retrieved_docs, api_key):\n",
    "    \"\"\"Generate an AI response using OpenAI GPT-4.\"\"\"\n",
    "    context = \"\\n\".join(retrieved_docs)\n",
    "    full_prompt = f\"Use the following documents to answer the question:\\n{context}\\n\\nQuestion: {prompt}\\nAnswer:\"\n",
    "    \n",
    "    openai.api_key = api_key\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": full_prompt}]\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def check_sentence_grounding(response, retrieved_docs):\n",
    "    \"\"\"Check if each sentence in the response is grounded in retrieved documents.\"\"\"\n",
    "    response_sentences = response.split(\". \")\n",
    "    retrieved_embeddings = model.encode(retrieved_docs, convert_to_numpy=True)\n",
    "    \n",
    "    results = []\n",
    "    for sentence in response_sentences:\n",
    "        sentence_embedding = model.encode([sentence], convert_to_numpy=True)\n",
    "        similarities = cosine_similarity(sentence_embedding, retrieved_embeddings)\n",
    "        max_sim = max(similarities[0])\n",
    "        is_grounded = max_sim > 0.7  # Threshold for similarity\n",
    "        results.append((sentence, is_grounded, max_sim))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def compute_grounding_score(results):\n",
    "    \"\"\"Calculate the percentage of grounded sentences.\"\"\"\n",
    "    grounded_count = sum(1 for _, grounded, _ in results if grounded)\n",
    "    total_sentences = len(results)\n",
    "    return grounded_count / total_sentences if total_sentences > 0 else 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"RAG Groundedness Detection\")\n",
    "    parser.add_argument(\"--query\", type=str, required=True, help=\"User question\")\n",
    "    parser.add_argument(\"--api_key\", type=str, required=True, help=\"OpenAI API Key\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Sample corpus\n",
    "    documents = [\n",
    "        \"Einstein developed the theory of relativity.\",\n",
    "        \"The speed of light is approximately 299,792,458 meters per second.\",\n",
    "        \"Black holes can warp spacetime.\"\n",
    "    ]\n",
    "    \n",
    "    # Build FAISS index\n",
    "    doc_embeddings = model.encode(documents, convert_to_numpy=True)\n",
    "    index = faiss.IndexFlatL2(doc_embeddings.shape[1])\n",
    "    index.add(np.array(doc_embeddings))\n",
    "    \n",
    "    # Retrieve documents & generate response\n",
    "    retrieved_docs = retrieve_documents(args.query, documents, index)\n",
    "    response = generate_response(args.query, retrieved_docs, args.api_key)\n",
    "    \n",
    "    # Check grounding & compute score\n",
    "    grounding_results = check_sentence_grounding(response, retrieved_docs)\n",
    "    grounding_score = compute_grounding_score(grounding_results)\n",
    "    \n",
    "    print(\"Generated Response:\\n\", response)\n",
    "    print(\"\\nGroundedness Score:\", grounding_score)\n",
    "    for sent, grounded, sim in grounding_results:\n",
    "        print(f\"Sentence: {sent}\\nGrounded: {grounded} (Similarity: {sim:.2f})\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
