{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import argparse\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "nli_model = pipeline(\"text-classification\", model=\"roberta-large-mnli\")\n",
    "\n",
    "def retrieve_legal_docs(query, documents, index, k=3):\n",
    "    \"\"\"Retrieve the top-k most relevant legal documents for a query.\"\"\"\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "    _, indices = index.search(query_embedding, k)\n",
    "    return [documents[i] for i in indices[0]]\n",
    "\n",
    "def generate_legal_response(prompt, retrieved_docs, api_key):\n",
    "    \"\"\"Generate a legal AI response using OpenAI GPT-4.\"\"\"\n",
    "    context = \"\\n\".join(retrieved_docs)\n",
    "    full_prompt = f\"Use the following legal texts to answer:\\n{context}\\n\\nQuestion: {prompt}\\nAnswer:\"\n",
    "    \n",
    "    openai.api_key = api_key\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": full_prompt}]\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def check_grounding(response, retrieved_docs):\n",
    "    \"\"\"Check if each sentence in the response is grounded in retrieved legal documents.\"\"\"\n",
    "    response_sentences = response.split(\". \")\n",
    "    results = []\n",
    "    \n",
    "    for sentence in response_sentences:\n",
    "        for doc in retrieved_docs:\n",
    "            nli_result = nli_model(f\"{doc} [SEP] {sentence}\")[0]\n",
    "            if nli_result['label'] == 'ENTAILMENT':\n",
    "                results.append((sentence, True))\n",
    "                break\n",
    "        else:\n",
    "            results.append((sentence, False))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def compute_grounding_score(results):\n",
    "    \"\"\"Calculate the percentage of sentences explicitly supported by retrieved legal documents.\"\"\"\n",
    "    grounded_count = sum(1 for _, grounded in results if grounded)\n",
    "    total_sentences = len(results)\n",
    "    return grounded_count / total_sentences if total_sentences > 0 else 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Legal RAG Groundedness Detection\")\n",
    "    parser.add_argument(\"--query\", type=str, required=True, help=\"Legal question\")\n",
    "    parser.add_argument(\"--api_key\", type=str, required=True, help=\"OpenAI API Key\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Sample legal corpus\n",
    "    documents = [\n",
    "        \"Under the Fourth Amendment, searches require a warrant unless exigent circumstances exist.\",\n",
    "        \"Contract law requires mutual assent for enforceability.\",\n",
    "        \"Habeas corpus provides the right to challenge unlawful detention.\"\n",
    "    ]\n",
    "    \n",
    "    # Build FAISS index\n",
    "    doc_embeddings = model.encode(documents, convert_to_numpy=True)\n",
    "    index = faiss.IndexFlatL2(doc_embeddings.shape[1])\n",
    "    index.add(np.array(doc_embeddings))\n",
    "    \n",
    "    # Retrieve documents & generate response\n",
    "    retrieved_docs = retrieve_legal_docs(args.query, documents, index)\n",
    "    response = generate_legal_response(args.query, retrieved_docs, args.api_key)\n",
    "    \n",
    "    # Check grounding & compute score\n",
    "    grounding_results = check_grounding(response, retrieved_docs)\n",
    "    grounding_score = compute_grounding_score(grounding_results)\n",
    "    \n",
    "    print(\"Generated Response:\\n\", response)\n",
    "    print(\"\\nGroundedness Score:\", grounding_score)\n",
    "    for sent, grounded in grounding_results:\n",
    "        print(f\"Sentence: {sent}\\nGrounded: {grounded}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
